name: AI PR CI Pipeline

on:
  push:
    branches: [main]
  pull_request:

permissions:
  contents: write
  pages: write
  id-token: write

jobs:
  # -----------------------------
  # CI: Tests + Security + Metrics
  # -----------------------------
  build-test:
    runs-on: ubuntu-latest
    outputs:
      risk_score: ${{ steps.metrics.outputs.risk_score }}
      pipeline_success: ${{ steps.metrics.outputs.pipeline_success }}
      avg_build_time: ${{ steps.metrics.outputs.avg_build_time }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest bandit jq

      - name: Record start time
        id: start
        run: echo "start_time=$(date +%s)" >> $GITHUB_ENV

      - name: Run Pytest
        id: pytest
        continue-on-error: true
        run: |
          pytest --maxfail=1 --disable-warnings -q > pytest_results.txt
          echo "pytest_exit=$?" >> $GITHUB_ENV

      - name: Run Bandit (security scan)
        id: bandit
        continue-on-error: true
        run: |
          bandit -r src > bandit_report.txt
          echo "bandit_exit=$?" >> $GITHUB_ENV

      - name: Collect Metrics
        id: metrics
        run: |
          end_time=$(date +%s)
          build_time=$((end_time - $start_time))
          build_min=$((build_time / 60))
          build_sec=$((build_time % 60))

          if [ "$pytest_exit" -eq 0 ] && [ "$bandit_exit" -eq 0 ]; then
            success=100
          elif [ "$pytest_exit" -eq 0 ] || [ "$bandit_exit" -eq 0 ]; then
            success=50
          else
            success=0
          fi

          issues=$(grep -c "Issue:" bandit_report.txt || true)
          tests_failed=$(grep -c "FAILED" pytest_results.txt || true)
          risk=$(( (issues * 5) + (tests_failed * 10) ))
          [ $risk -gt 100 ] && risk=100

          echo "risk_score=$risk" >> $GITHUB_OUTPUT
          echo "pipeline_success=$success" >> $GITHUB_OUTPUT
          echo "avg_build_time=${build_min}m${build_sec}s" >> $GITHUB_OUTPUT

  # -----------------------------
  # Post metrics as PR comment
  # -----------------------------
  comment-metrics:
    needs: build-test
    if: github.event_name == 'pull_request'
    runs-on: ubuntu-latest
    steps:
      - name: Comment Risk Score & Build Stats
        uses: actions/github-script@v6
        with:
          script: |
            const risk = "${{needs.build-test.outputs.risk_score}}";
            const success = "${{needs.build-test.outputs.pipeline_success}}";
            const time = "${{needs.build-test.outputs.avg_build_time}}";
            const body = `
            ### ðŸš¦ CI Metrics
            | Metric | Value |
            |--------|-------|
            | Risk Score | ${risk} / 100 |
            | Pipeline Success | ${success}% |
            | Avg Build Time | ${time} |
            `;
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body
            });

  # -----------------------------
  # AI PR Agent Review
  # -----------------------------
  pr-agent:
    needs: build-test
    if: github.event_name == 'pull_request'
    runs-on: ubuntu-latest
    outputs:
      ai_approved: ${{ steps.set-approval.outputs.ai_approved }}
    steps:
      - name: Run PR Agent
        uses: Codium-ai/pr-agent@main
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Decide AI approval
        id: set-approval
        run: |
          if [[ "${{ needs.build-test.outputs.risk_score }}" -le 30 ]]; then
            echo "ai_approved=true" >> $GITHUB_OUTPUT
          else
            echo "ai_approved=false" >> $GITHUB_OUTPUT

  # -----------------------------
  # Auto-merge if low risk
  # -----------------------------
  auto-merge:
    needs: [build-test, pr-agent]
    if: needs.pr-agent.outputs.ai_approved == 'true' && needs.build-test.outputs.pipeline_success == '100'
    runs-on: ubuntu-latest
    steps:
      - name: Auto-merge PR
        uses: pascalgn/automerge-action@v0.16.3
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  # -----------------------------
  # Publish PR Summary JSON â†’ GitHub Pages
  # -----------------------------
  publish-dashboard:
    needs: [build-test, pr-agent, auto-merge]
    if: github.event_name == 'pull_request'
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Generate JSON files
        run: |
          mkdir -p public
          cat <<EOF > public/pr_summary_${{ github.event.pull_request.number }}.json
          {
            "pr_number": "${{ github.event.pull_request.number }}",
            "title": "${{ github.event.pull_request.title }}",
            "risk_score": "${{ needs.build-test.outputs.risk_score }}",
            "pipeline_success": "${{ needs.build-test.outputs.pipeline_success }}",
            "avg_build_time": "${{ needs.build-test.outputs.avg_build_time }}",
            "ai_approved": "${{ needs.pr-agent.outputs.ai_approved }}",
            "auto_merge": "${{ (needs.pr-agent.outputs.ai_approved == 'true' && needs.build-test.outputs.pipeline_success == '100') && 'yes' || 'no' }}"
          }
          EOF

          cp public/pr_summary_${{ github.event.pull_request.number }}.json public/latest.json

      - name: Upload artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: public

  deploy-pages:
    needs: publish-dashboard
    runs-on: ubuntu-latest
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
